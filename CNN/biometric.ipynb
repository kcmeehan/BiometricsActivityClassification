{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution1D, MaxPooling1D\n",
    "from keras import metrics\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import DataProcessCNN as DP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for subj_n in range(1,10):\n",
    "    #load the data\n",
    "#    subj_filename='C:/Users/lt/Desktop/DSW2018/PAMAP2_Dataset/Protocol/subject10'+str(subj_n)+'.dat'\n",
    "#    dp=DP.dataprocess(subj_filename)\n",
    "#    np.save('data'+str(subj_n)+'.npy', (DP.col_sublabels,dp.data_segmented))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datalabels=[]\n",
    "for i in range(1,10):\n",
    "    feature_names,datalabelsi=np.load('data'+str(i)+'.npy')\n",
    "    datalabels.append(datalabelsi)\n",
    "\n",
    "datalabels=np.vstack(datalabels)\n",
    "\n",
    "act_list=np.unique(datalabels[:,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all=datalabels[:,:,2:]\n",
    "y_all=datalabels[:,0,1]\n",
    "\n",
    "y_all2=np.zeros(len(y_all))\n",
    "for i in range(12):\n",
    "    y_all2[np.where(y_all==act_list[i])]=i\n",
    "\n",
    "#convert to float32\n",
    "X_all = X_all.astype('float32')\n",
    "\n",
    "# convert labels to class matrix, one-hot-encoding\n",
    "Y_all = np_utils.to_categorical(y_all2,12)\n",
    "# split in train and test set\n",
    "X_train, x_test, Y_train, y_test = train_test_split(X_all, Y_all, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train.reshape(len(X_train)*512,31))\n",
    "\n",
    "X_trainnorm=(X_train-scaler.mean_)/scaler.scale_\n",
    "x_testnorm=(x_test-scaler.mean_)/scaler.scale_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution1D(16, 3, activation='relu', input_shape=(512,31)))\n",
    "model.add(MaxPooling1D(3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(12, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2664 samples, validate on 666 samples\n",
      "Epoch 1/10\n",
      "2664/2664 [==============================] - 2s 616us/step - loss: 1.1506 - acc: 0.6175 - val_loss: 0.5463 - val_acc: 0.8168\n",
      "Epoch 2/10\n",
      "2664/2664 [==============================] - 1s 493us/step - loss: 0.2950 - acc: 0.9122 - val_loss: 0.2499 - val_acc: 0.9234\n",
      "Epoch 3/10\n",
      "2664/2664 [==============================] - 1s 493us/step - loss: 0.1311 - acc: 0.9640 - val_loss: 0.1840 - val_acc: 0.9429\n",
      "Epoch 4/10\n",
      "2664/2664 [==============================] - 1s 476us/step - loss: 0.0745 - acc: 0.9824 - val_loss: 0.1509 - val_acc: 0.9535\n",
      "Epoch 5/10\n",
      "2664/2664 [==============================] - 1s 498us/step - loss: 0.0478 - acc: 0.9869 - val_loss: 0.1366 - val_acc: 0.9610\n",
      "Epoch 6/10\n",
      "2664/2664 [==============================] - 1s 498us/step - loss: 0.0235 - acc: 0.9959 - val_loss: 0.1171 - val_acc: 0.9655\n",
      "Epoch 7/10\n",
      "2664/2664 [==============================] - 1s 498us/step - loss: 0.0168 - acc: 0.9970 - val_loss: 0.1111 - val_acc: 0.9640\n",
      "Epoch 8/10\n",
      "2664/2664 [==============================] - 1s 498us/step - loss: 0.0096 - acc: 0.9989 - val_loss: 0.1091 - val_acc: 0.9685\n",
      "Epoch 9/10\n",
      "2664/2664 [==============================] - 1s 481us/step - loss: 0.0074 - acc: 0.9992 - val_loss: 0.1010 - val_acc: 0.9730\n",
      "Epoch 10/10\n",
      "2664/2664 [==============================] - 1s 498us/step - loss: 0.0053 - acc: 0.9996 - val_loss: 0.1018 - val_acc: 0.9685\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b408df3748>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_trainnorm, Y_train, validation_data=(x_testnorm,y_test), epochs=10, batch_size=16,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
