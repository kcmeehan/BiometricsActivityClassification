{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carry out Tree based feature selection, feature selection with the Genetic Algorithm and LOSO with a random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rmartinshort/anaconda2/envs/python3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate, GridSearchCV, train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from parameter_feature_search import *\n",
    "import glob\n",
    "import time\n",
    "import pandas as pd\n",
    "from plotting_tools import plot_feature_distributions\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import warnings\n",
    "import DataProcess as DP\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can choose to use just the protocol or just the optional datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "protocol_datadir = '/home/rmartinshort/Documents/Berkeley/GDSO/PAMAP2_Dataset/Protocol/'\n",
    "optional_datadir = '/home/rmartinshort/Documents/Berkeley/GDSO/PAMAP2_Dataset/Optional/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rmartinshort/Documents/Berkeley/GDSO/PAMAP2_Dataset/Protocol/subject101.dat\n",
      "/home/rmartinshort/Documents/Berkeley/GDSO/PAMAP2_Dataset/Protocol/subject107.dat\n",
      "/home/rmartinshort/Documents/Berkeley/GDSO/PAMAP2_Dataset/Protocol/subject105.dat\n",
      "/home/rmartinshort/Documents/Berkeley/GDSO/PAMAP2_Dataset/Protocol/subject106.dat\n",
      "/home/rmartinshort/Documents/Berkeley/GDSO/PAMAP2_Dataset/Protocol/subject103.dat\n",
      "/home/rmartinshort/Documents/Berkeley/GDSO/PAMAP2_Dataset/Protocol/subject109.dat\n",
      "/home/rmartinshort/Documents/Berkeley/GDSO/PAMAP2_Dataset/Protocol/subject104.dat\n",
      "/home/rmartinshort/Documents/Berkeley/GDSO/PAMAP2_Dataset/Protocol/subject102.dat\n",
      "/home/rmartinshort/Documents/Berkeley/GDSO/PAMAP2_Dataset/Protocol/subject108.dat\n",
      "/home/rmartinshort/Documents/Berkeley/GDSO/PAMAP2_Dataset/Optional/subject101.dat\n",
      "/home/rmartinshort/Documents/Berkeley/GDSO/PAMAP2_Dataset/Optional/subject105.dat\n",
      "/home/rmartinshort/Documents/Berkeley/GDSO/PAMAP2_Dataset/Optional/subject106.dat\n",
      "/home/rmartinshort/Documents/Berkeley/GDSO/PAMAP2_Dataset/Optional/subject109.dat\n",
      "/home/rmartinshort/Documents/Berkeley/GDSO/PAMAP2_Dataset/Optional/subject108.dat\n"
     ]
    }
   ],
   "source": [
    "allfiles = list(glob.glob(protocol_datadir+'*.dat'))+list(glob.glob(optional_datadir+'*.dat'))\n",
    "\n",
    "all_dfs = []\n",
    "for fname in allfiles:\n",
    "    print(fname)\n",
    "    subject_index = int(fname.split('/')[-1].split('.')[0][-1])\n",
    "    dp = DP.dataprocess(fname,T=512,stride=512)\n",
    "    \n",
    "    #For LOSO, we need subjectID in the final dataframe\n",
    "    dp.df['subjectID'] = int(subject_index)*np.ones(len(dp.df))\n",
    "    all_dfs.append(dp.df)\n",
    "    \n",
    "feature_df = pd.concat(all_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df.to_csv(\"Features_df_with_subject.dat\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load features dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = pd.read_csv(\"Features_df_with_subject.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = feature_df['activityID']\n",
    "X = feature_df.drop(['activityID','subjectID'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale the input matrix and generate classification labels from the target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_scaled = pd.DataFrame(sc.fit_transform(X),columns=X.columns)\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up inputs for initial hyperparameter search function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()\n",
    "\n",
    "parameters = {\n",
    "    'classify__n_estimators': (85,95,100,105),\n",
    "    'classify__max_depth': (10,20,30,50,None),\n",
    "    'classify__class_weight':(\"balanced\",\"balanced_subsample\",None),\n",
    "    'classify__criterion':('gini','entropy')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select optimal hyperparemeters and an estimate of the best feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['select', 'classify']\n",
      "parameters:\n",
      "{'classify__n_estimators': (85, 95, 100, 105), 'classify__max_depth': (10, 20, 30, 50, None), 'classify__class_weight': ('balanced', 'balanced_subsample', None), 'classify__criterion': ('gini', 'entropy')}\n",
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  1.1min\n"
     ]
    }
   ],
   "source": [
    "X_new, best_classifier = test_model_initial(model,X_scaled,labels,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_new.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the best classifier without selecting feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select optimal feature columns using genetic algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-5c7e900d89b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mGA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRun_GA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_scaled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_classifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Berkeley/GDSO/BiometricsActivityClassification/master_features_workflow/parameter_feature_search.py\u001b[0m in \u001b[0;36mRun_GA\u001b[0;34m(X, Y, classifier)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mGA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGeneticAlgorithm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mnjobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0mGA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mGA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Berkeley/GDSO/BiometricsActivityClassification/master_features_workflow/GeneticAlgorithm.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mold_fitness_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_generation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_fitness_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/python3/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m   2318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m     return _methods._amax(a, axis=axis,\n\u001b[0;32m-> 2320\u001b[0;31m                           out=out, **kwargs)\n\u001b[0m\u001b[1;32m   2321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/python3/lib/python3.6/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_amax\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# small reductions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_amax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_maximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_amin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "GA = Run_GA(X_scaled,labels,best_classifier)\n",
    "t2 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(GA.fitness_evolution)\n",
    "ax.set_xlabel('GA Iteration')\n",
    "ax.set_ylabel('Test score')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-28b3e444d002>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mGA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_fitness\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'GA' is not defined"
     ]
    }
   ],
   "source": [
    "GA.best_fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(GA.feature_selection.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do LOSO on the original feature columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features = X\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_features_scaled = pd.DataFrame(sc.fit_transform(X_features),columns=X_features.columns)\n",
    "X_features_scaled['activityID'] = feature_df['activityID'].values\n",
    "X_features_scaled['subjectID'] = feature_df['subjectID'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holding out subject 6\n",
      "----------------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       1.00      1.00      1.00        28\n",
      "        2.0       0.24      1.00      0.38        24\n",
      "        3.0       0.74      0.65      0.69        26\n",
      "        4.0       1.00      0.93      0.96        27\n",
      "        5.0       1.00      1.00      1.00        25\n",
      "        6.0       1.00      1.00      1.00        26\n",
      "        7.0       0.97      1.00      0.99        36\n",
      "       10.0       0.33      0.03      0.05        79\n",
      "       12.0       0.69      1.00      0.82         9\n",
      "       13.0       1.00      1.00      1.00         9\n",
      "       16.0       0.69      0.92      0.79        26\n",
      "       17.0       0.59      0.94      0.72        50\n",
      "       18.0       0.00      0.00      0.00        29\n",
      "       19.0       0.88      0.56      0.69        39\n",
      "\n",
      "avg / total       0.67      0.68      0.63       433\n",
      "\n",
      "----------------------------------------------------\n",
      "Holding out subject 8\n",
      "----------------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       1.00      1.00      1.00        32\n",
      "        2.0       0.26      1.00      0.42        27\n",
      "        3.0       0.51      0.92      0.66        26\n",
      "        4.0       0.95      1.00      0.97        37\n",
      "        5.0       0.71      1.00      0.83        17\n",
      "        6.0       1.00      1.00      1.00        34\n",
      "        7.0       1.00      1.00      1.00        37\n",
      "       10.0       1.00      0.02      0.04        95\n",
      "       12.0       0.83      1.00      0.91        10\n",
      "       13.0       0.62      1.00      0.77         5\n",
      "       16.0       0.94      0.94      0.94        31\n",
      "       17.0       0.56      0.93      0.70        46\n",
      "       18.0       0.00      0.00      0.00        34\n",
      "       19.0       0.63      0.65      0.64        49\n",
      "       20.0       1.00      0.16      0.27        19\n",
      "       24.0       1.00      1.00      1.00         8\n",
      "\n",
      "avg / total       0.77      0.67      0.60       507\n",
      "\n",
      "----------------------------------------------------\n",
      "Holding out subject 3\n",
      "----------------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       1.00      1.00      1.00        25\n",
      "        2.0       0.90      1.00      0.95        36\n",
      "        3.0       0.81      0.77      0.79        22\n",
      "        4.0       1.00      1.00      1.00        38\n",
      "       10.0       0.00      0.00      0.00         0\n",
      "       12.0       1.00      1.00      1.00         9\n",
      "       13.0       1.00      1.00      1.00        14\n",
      "       16.0       1.00      0.35      0.51        26\n",
      "       17.0       1.00      0.17      0.29        36\n",
      "       18.0       0.00      0.00      0.00         0\n",
      "       19.0       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.96      0.75      0.78       206\n",
      "\n",
      "----------------------------------------------------\n",
      "Holding out subject 4\n",
      "----------------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       1.00      1.00      1.00        33\n",
      "        2.0       1.00      1.00      1.00        30\n",
      "        3.0       1.00      1.00      1.00        25\n",
      "        4.0       0.97      1.00      0.99        36\n",
      "        6.0       0.96      0.96      0.96        25\n",
      "        7.0       1.00      1.00      1.00        35\n",
      "       12.0       1.00      1.00      1.00        14\n",
      "       13.0       1.00      0.93      0.96        14\n",
      "       16.0       0.96      0.93      0.95        28\n",
      "       17.0       1.00      0.54      0.70        37\n",
      "       18.0       0.00      0.00      0.00         0\n",
      "       19.0       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.99      0.92      0.95       277\n",
      "\n",
      "----------------------------------------------------\n",
      "Holding out subject 1\n",
      "----------------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.88      0.93      0.90        30\n",
      "        2.0       0.04      0.06      0.05        33\n",
      "        3.0       0.24      0.68      0.35        25\n",
      "        4.0       1.00      1.00      1.00        30\n",
      "        5.0       1.00      1.00      1.00        28\n",
      "        6.0       1.00      1.00      1.00        29\n",
      "        7.0       1.00      1.00      1.00        23\n",
      "        9.0       0.00      0.00      0.00       111\n",
      "       10.0       0.00      0.00      0.00         0\n",
      "       11.0       0.00      0.00      0.00        72\n",
      "       12.0       1.00      1.00      1.00        13\n",
      "       13.0       1.00      1.00      1.00        17\n",
      "       16.0       0.25      1.00      0.39        29\n",
      "       17.0       0.27      0.38      0.31        32\n",
      "       18.0       0.00      0.00      0.00        36\n",
      "       19.0       0.00      0.00      0.00        75\n",
      "       20.0       0.00      0.00      0.00         0\n",
      "       24.0       1.00      0.93      0.96        14\n",
      "\n",
      "avg / total       0.34      0.40      0.36       597\n",
      "\n",
      "----------------------------------------------------\n",
      "Holding out subject 9\n",
      "----------------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        4.0       0.00      0.00      0.00         0\n",
      "        5.0       0.00      0.00      0.00         0\n",
      "       10.0       1.00      0.96      0.98        90\n",
      "       16.0       0.00      0.00      0.00         0\n",
      "       17.0       0.00      0.00      0.00         0\n",
      "       18.0       0.00      0.00      0.00        38\n",
      "       19.0       1.00      0.18      0.31        44\n",
      "       20.0       1.00      0.72      0.84        40\n",
      "       24.0       1.00      1.00      1.00         5\n",
      "\n",
      "avg / total       0.82      0.59      0.65       217\n",
      "\n",
      "----------------------------------------------------\n",
      "Holding out subject 2\n",
      "----------------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       1.00      0.95      0.98        22\n",
      "        2.0       1.00      0.90      0.95        30\n",
      "        3.0       1.00      1.00      1.00        32\n",
      "        4.0       0.85      1.00      0.92        40\n",
      "        5.0       0.00      0.00      0.00         9\n",
      "        6.0       1.00      1.00      1.00        37\n",
      "        7.0       1.00      0.85      0.92        39\n",
      "       10.0       0.00      0.00      0.00         0\n",
      "       12.0       1.00      1.00      1.00        16\n",
      "       13.0       1.00      0.93      0.97        15\n",
      "       16.0       0.96      1.00      0.98        24\n",
      "       17.0       1.00      0.95      0.97        37\n",
      "       19.0       0.00      0.00      0.00         0\n",
      "       20.0       0.00      0.00      0.00         0\n",
      "       24.0       1.00      1.00      1.00        12\n",
      "\n",
      "avg / total       0.95      0.93      0.94       313\n",
      "\n",
      "----------------------------------------------------\n",
      "Holding out subject 7\n",
      "----------------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       1.00      1.00      1.00        32\n",
      "        2.0       1.00      1.00      1.00        13\n",
      "        3.0       1.00      1.00      1.00        31\n",
      "        4.0       0.98      0.98      0.98        43\n",
      "        5.0       1.00      1.00      1.00         3\n",
      "        6.0       1.00      0.97      0.98        31\n",
      "        7.0       0.97      1.00      0.99        36\n",
      "       12.0       1.00      0.95      0.97        20\n",
      "       13.0       1.00      1.00      1.00        12\n",
      "       16.0       1.00      0.52      0.68        29\n",
      "       17.0       0.94      0.97      0.96        35\n",
      "       19.0       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.99      0.94      0.95       285\n",
      "\n",
      "----------------------------------------------------\n",
      "Holding out subject 5\n",
      "----------------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.93      0.96      0.95        28\n",
      "        2.0       0.43      0.90      0.58        40\n",
      "        3.0       0.47      0.81      0.59        27\n",
      "        4.0       1.00      1.00      1.00        41\n",
      "        5.0       1.00      0.97      0.98        30\n",
      "        6.0       1.00      0.93      0.97        30\n",
      "        7.0       1.00      1.00      1.00        32\n",
      "       10.0       1.00      0.53      0.69       143\n",
      "       11.0       0.00      0.00      0.00         0\n",
      "       12.0       1.00      1.00      1.00        11\n",
      "       13.0       1.00      0.93      0.96        14\n",
      "       16.0       0.74      0.88      0.81        33\n",
      "       17.0       0.69      0.92      0.79        37\n",
      "       19.0       0.50      0.26      0.34        35\n",
      "       20.0       0.00      0.00      0.00         0\n",
      "       24.0       1.00      1.00      1.00         7\n",
      "\n",
      "avg / total       0.85      0.78      0.78       508\n",
      "\n",
      "----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "subject_scores_no_selection = LOSO(X_features_scaled,best_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1.0': 0.4036850921273032,\n",
       " '2.0': 0.9297124600638977,\n",
       " '3.0': 0.7475728155339806,\n",
       " '4.0': 0.924187725631769,\n",
       " '5.0': 0.7755905511811023,\n",
       " '6.0': 0.6789838337182448,\n",
       " '7.0': 0.9368421052631579,\n",
       " '8.0': 0.6706114398422091,\n",
       " '9.0': 0.5898617511520737}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_scores_no_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_LOSO_no_selection = np.mean([subject_scores_no_selection[e] for e in list(subject_scores_no_selection.keys())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do LOSO on the feature columns selected by the GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features_GA = list(GA.feature_columns) + ['activityID','subjectID']\n",
    "X_feature_select_GA = feature_df[new_features_GA]\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_feature_select_GA_scaled = pd.DataFrame(sc.fit_transform(X_feature_select_GA),columns=X_feature_select_GA.columns)\n",
    "X_feature_select_GA_scaled['activityID'] = X_feature_select_GA['activityID'].values\n",
    "X_feature_select_GA_scaled['subjectID'] = X_feature_select_GA['subjectID'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holding out subject 1\n",
      "Holding out subject 6\n",
      "Holding out subject 5\n",
      "Holding out subject 8\n",
      "Holding out subject 9\n"
     ]
    }
   ],
   "source": [
    "subject_scores_GA_selection = LOSO(X_feature_select_GA_scaled,best_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1.0': 0.2048611111111111,\n",
       " '5.0': 0.9606741573033708,\n",
       " '6.0': 0.8266666666666667,\n",
       " '8.0': 0.7849462365591398,\n",
       " '9.0': 0.9619047619047619}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_scores_GA_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_LOSO_GA = np.mean([subject_scores_GA_selection[e] for e in list(subject_scores_GA_selection.keys())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do LOSO on the feature columns selected by the tree-based proceedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features_Treebased = list(X_new.columns) + ['activityID','subjectID']\n",
    "X_feature_select_Treebased = feature_df[new_features_Treebased]\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_feature_select_Treebased_scaled = pd.DataFrame(sc.fit_transform(X_feature_select_Treebased),columns=X_feature_select_Treebased.columns)\n",
    "X_feature_select_Treebased_scaled['activityID'] = X_feature_select_Treebased['activityID']\n",
    "X_feature_select_Treebased_scaled['subjectID'] = X_feature_select_Treebased['subjectID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holding out subject 8\n",
      "----------------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       1.00      1.00      1.00        36\n",
      "        2.0       0.83      1.00      0.91        29\n",
      "        3.0       0.37      0.97      0.53        33\n",
      "        4.0       0.98      1.00      0.99        44\n",
      "        5.0       0.66      1.00      0.79        21\n",
      "        6.0       0.97      1.00      0.98        31\n",
      "        7.0       1.00      1.00      1.00        39\n",
      "       10.0       1.00      0.36      0.53        89\n",
      "       12.0       0.75      1.00      0.86         9\n",
      "       13.0       0.70      1.00      0.82         7\n",
      "       16.0       0.91      0.97      0.94        33\n",
      "       17.0       0.49      1.00      0.66        43\n",
      "       18.0       0.00      0.00      0.00        29\n",
      "       19.0       0.90      0.55      0.68        51\n",
      "       20.0       0.00      0.00      0.00        20\n",
      "       24.0       1.00      1.00      1.00         7\n",
      "\n",
      "avg / total       0.77      0.75      0.71       521\n",
      "\n",
      "----------------------------------------------------\n",
      "Holding out subject 3\n",
      "----------------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       1.00      1.00      1.00        23\n",
      "        2.0       0.89      0.97      0.93        40\n",
      "        3.0       0.86      0.78      0.82        23\n",
      "        4.0       0.95      1.00      0.97        37\n",
      "       10.0       0.00      0.00      0.00         0\n",
      "       12.0       1.00      0.75      0.86         8\n",
      "       13.0       1.00      1.00      1.00         9\n",
      "       16.0       0.00      0.00      0.00        23\n",
      "       17.0       0.00      0.00      0.00        34\n",
      "       18.0       0.00      0.00      0.00         0\n",
      "       19.0       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.66      0.67      0.66       197\n",
      "\n",
      "----------------------------------------------------\n",
      "Holding out subject 1\n",
      "----------------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.54      0.94      0.69        35\n",
      "        2.0       0.04      0.06      0.05        33\n",
      "        3.0       0.30      0.65      0.41        26\n",
      "        4.0       1.00      1.00      1.00        28\n",
      "        5.0       1.00      1.00      1.00        26\n",
      "        6.0       0.96      1.00      0.98        27\n",
      "        7.0       1.00      1.00      1.00        23\n",
      "        9.0       0.00      0.00      0.00       118\n",
      "       10.0       0.00      0.00      0.00         0\n",
      "       11.0       0.00      0.00      0.00        66\n",
      "       12.0       1.00      1.00      1.00        10\n",
      "       13.0       1.00      1.00      1.00        14\n",
      "       16.0       0.28      1.00      0.43        28\n",
      "       17.0       0.15      0.16      0.16        25\n",
      "       18.0       0.00      0.00      0.00        31\n",
      "       19.0       0.00      0.00      0.00        60\n",
      "       24.0       1.00      1.00      1.00        13\n",
      "\n",
      "avg / total       0.32      0.40      0.34       563\n",
      "\n",
      "----------------------------------------------------\n",
      "Holding out subject 2\n",
      "----------------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       1.00      0.96      0.98        26\n",
      "        2.0       1.00      0.91      0.95        32\n",
      "        3.0       0.97      0.97      0.97        33\n",
      "        4.0       0.87      1.00      0.93        45\n",
      "        5.0       0.00      0.00      0.00        11\n",
      "        6.0       1.00      1.00      1.00        40\n",
      "        7.0       1.00      0.81      0.89        36\n",
      "       12.0       1.00      1.00      1.00        17\n",
      "       13.0       1.00      1.00      1.00        13\n",
      "       16.0       0.89      1.00      0.94        25\n",
      "       17.0       0.97      0.97      0.97        37\n",
      "       19.0       0.00      0.00      0.00         0\n",
      "       20.0       0.00      0.00      0.00         0\n",
      "       24.0       1.00      1.00      1.00        15\n",
      "\n",
      "avg / total       0.93      0.93      0.93       330\n",
      "\n",
      "----------------------------------------------------\n",
      "Holding out subject 4\n",
      "----------------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       1.00      1.00      1.00        28\n",
      "        2.0       1.00      1.00      1.00        30\n",
      "        3.0       1.00      0.96      0.98        27\n",
      "        4.0       1.00      1.00      1.00        38\n",
      "        6.0       0.97      1.00      0.98        28\n",
      "        7.0       1.00      1.00      1.00        35\n",
      "       12.0       1.00      0.94      0.97        18\n",
      "       13.0       1.00      1.00      1.00        15\n",
      "       16.0       0.96      0.96      0.96        24\n",
      "       17.0       1.00      0.74      0.85        23\n",
      "       18.0       0.00      0.00      0.00         0\n",
      "       19.0       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.99      0.97      0.98       266\n",
      "\n",
      "----------------------------------------------------\n",
      "Holding out subject 7\n",
      "----------------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       1.00      1.00      1.00        35\n",
      "        2.0       1.00      1.00      1.00        14\n",
      "        3.0       1.00      1.00      1.00        34\n",
      "        4.0       0.96      1.00      0.98        49\n",
      "        5.0       1.00      1.00      1.00         1\n",
      "        6.0       1.00      1.00      1.00        28\n",
      "        7.0       1.00      1.00      1.00        39\n",
      "       10.0       0.00      0.00      0.00         0\n",
      "       12.0       1.00      0.88      0.93        16\n",
      "       13.0       1.00      1.00      1.00        10\n",
      "       16.0       1.00      0.38      0.55        29\n",
      "       17.0       0.93      0.70      0.80        40\n",
      "       18.0       0.00      0.00      0.00         0\n",
      "       19.0       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.98      0.89      0.92       295\n",
      "\n",
      "----------------------------------------------------\n",
      "Holding out subject 5\n",
      "----------------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       1.00      1.00      1.00        31\n",
      "        2.0       0.77      1.00      0.87        30\n",
      "        3.0       0.71      0.83      0.77        30\n",
      "        4.0       1.00      1.00      1.00        41\n",
      "        5.0       1.00      0.26      0.41        23\n",
      "        6.0       1.00      0.87      0.93        31\n",
      "        7.0       1.00      1.00      1.00        33\n",
      "       10.0       1.00      0.93      0.96       156\n",
      "       11.0       0.00      0.00      0.00         0\n",
      "       12.0       0.76      1.00      0.87        13\n",
      "       13.0       0.37      0.83      0.51        12\n",
      "       16.0       0.62      0.83      0.71        24\n",
      "       17.0       0.80      0.97      0.88        37\n",
      "       18.0       0.00      0.00      0.00         0\n",
      "       19.0       0.68      0.38      0.49        39\n",
      "       24.0       1.00      0.71      0.83         7\n",
      "\n",
      "avg / total       0.89      0.86      0.86       507\n",
      "\n",
      "----------------------------------------------------\n",
      "Holding out subject 6\n",
      "----------------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       1.00      1.00      1.00        29\n",
      "        2.0       0.25      1.00      0.40        27\n",
      "        3.0       0.72      0.72      0.72        32\n",
      "        4.0       1.00      0.85      0.92        33\n",
      "        5.0       1.00      1.00      1.00        29\n",
      "        6.0       0.89      1.00      0.94        25\n",
      "        7.0       1.00      1.00      1.00        38\n",
      "       10.0       0.17      0.01      0.02        84\n",
      "       12.0       0.68      1.00      0.81        15\n",
      "       13.0       1.00      1.00      1.00        12\n",
      "       16.0       0.85      0.92      0.88        24\n",
      "       17.0       0.61      0.92      0.73        49\n",
      "       18.0       0.00      0.00      0.00        27\n",
      "       19.0       0.88      0.67      0.76        33\n",
      "\n",
      "avg / total       0.65      0.69      0.64       457\n",
      "\n",
      "----------------------------------------------------\n",
      "Holding out subject 9\n",
      "----------------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        4.0       0.00      0.00      0.00         0\n",
      "        5.0       0.00      0.00      0.00         0\n",
      "        6.0       0.00      0.00      0.00         0\n",
      "       10.0       1.00      0.97      0.98        88\n",
      "       16.0       0.00      0.00      0.00         0\n",
      "       17.0       0.00      0.00      0.00         0\n",
      "       18.0       0.00      0.00      0.00        28\n",
      "       19.0       1.00      0.11      0.20        46\n",
      "       20.0       1.00      0.55      0.71        38\n",
      "       24.0       1.00      1.00      1.00         7\n",
      "\n",
      "avg / total       0.86      0.57      0.63       207\n",
      "\n",
      "----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "subject_scores_Treebased_selection = LOSO(X_feature_select_Treebased,best_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1.0': 0.3996447602131439,\n",
       " '2.0': 0.9272727272727272,\n",
       " '3.0': 0.6700507614213198,\n",
       " '4.0': 0.9661654135338346,\n",
       " '5.0': 0.8619329388560157,\n",
       " '6.0': 0.6914660831509847,\n",
       " '7.0': 0.8915254237288136,\n",
       " '8.0': 0.7485604606525912,\n",
       " '9.0': 0.5700483091787439}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_scores_Treebased_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_LOSO_Treebased = np.mean([subject_scores_Treebased_selection[e] for e in list(subject_scores_Treebased_selection.keys())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare final scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean LOSO score for tree-based selection: 0.747\n",
      "Mean LOSO score for no feature selection: 0.740\n"
     ]
    }
   ],
   "source": [
    "print('Mean LOSO score for tree-based selection: %0.3f' %mean_LOSO_Treebased)\n",
    "#print('Mean LOSO score for GA-based selection: %0.3f' %mean_LOSO_GA)\n",
    "print('Mean LOSO score for no feature selection: %0.3f' %mean_LOSO_no_selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: LOSO is a tough problem. Optimal selection of feature columns doesn't make much difference to the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
